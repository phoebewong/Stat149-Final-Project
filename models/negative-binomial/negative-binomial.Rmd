---
title: "negative-binomial-submit"
author: "Phoebe Wong"
date: "4/29/2019"
output: 
  html_document:
    theme: flatly
    highlight: tango
    toc: true
    toc_float: true
    fig_width: 6
    fig_height: 4
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels) # train test split
library(MASS)
library(car)
```

# Preprocessing
- mean-imputed on charges and added charges.na
- Drop `Patient` ID column because of irrelevance
- Drop `DIED` column because of perfect colinearity with `DRG` (`DRG` == 123 when `DIED` == 1) 
```{r load-data}
ami <- readRDS("../../data/amidata_clean.rds") %>%
  dplyr::select(-one_of(c("patient", "died")))# drop patient ID column

# ami[ami$los == 0, ]
table(ami$los)[1:15]
```
We then split our dataset into train and test set for test-set performance measurement later
```{r train-test-split}
set.seed(42)
ami_split <- initial_split(ami, prop = .8, strata = "los") # Stratified sampling based on LOS

ami_train <- training(ami_split)
ami_test  <- testing(ami_split)

nrow(ami_train)/nrow(ami)
```

# Model on mean-imputed data
```{r step-noint}
step_noint <- stats::step(glm.nb(los ~ .,  data=ami_train), trace=0, direction='both')
step_noint
```

We then fit the negative binomial model with the variables picked by the stepwise regression
(`r as.character(formula(step_noint))[3]`)

```{r}
mod_nb_noint <- glm.nb(formula(step_noint), data = ami)
summary(mod_nb_noint)
```
Because both `charges` and `charges.na` are significant predictors in the model, we proceeded with the data with mean-imputed missing values.

The ratio of residual deviance to residual degrees of freedom (12832/12829) indicates a good fit of the model to the data.

    
```{r step-withint}
step_withint <- stats::step(glm.nb(los ~ .^2., data=ami_train), trace=0, direction='both')
step_withint
```

We then fit the negative binomial model with the variables picked by the stepwise regression
(`r as.character(formula(step_withint))[3]`)

```{r mod-withint}
mod_nb_withint <- glm.nb(formula(step_withint), data = ami_train)
summary(mod_nb_withint)
```

Note that `charges` and `charges.na` are both significant in this model. 

The ratio of residual deviance to residual degrees of freedom (12733/12768) indicates a good fit of the model to the data.

# Likelihood ratio test of the two models
```{r anova}
anova(mod_nb_noint, mod_nb_withint)
```

From the above likelihood ratio test, we can see that the model with interaction terms is significantly different than the model without interaction terms. Therefore, we proceed with the model with interaction terms

# Model Diagnosis
## Residual plot and Cook's Distance
```{r res-plot}
par(mfrow=c(1,2))
# Residuals plot
plot(residuals(mod_nb_withint)~fitted(mod_nb_withint),
     xlab="Fitted Values",
     ylab="Residual Values", 
     main="Residual vs. Fitted Values Plot")
abline(h = -2, lty = 2, col = 'red')
abline(h = 2, lty = 2, col = 'red')

plot(cooks.distance(mod_nb_withint), type="h", lwd=2,
  xlab="Observation index",
  ylab="Cook's distances",
  main="Cook's Distances Plot")
abline(h=1,lty=2,col="red")
```

## Colinearity

```{r}
car::vif(mod_nb_withint)
```

There are a number of terms with a GVIF^(1/(2*Df)) greater than $\sqrt{10}$ (3.16), though we suspect this is due to the presence of interaction terms. We therefore fit the baseline model without interaction terms and redid the VIF inspection.

```{r}
model_noint_baseline = glm.nb(formula = los ~ diagnosis + sex + drg + charges + age + charges.na , data = ami_train)
car::vif(model_noint_baseline)
```

These values are all much less than $\sqrt{10}$, suggesting there is no multicollinearity in the base predictors, and the multicollinearity present in the full model comes from the interaction terms.

## GAM
```{r, include=FALSE}
library(mgcv)

add_spline <- function(var, k=NULL){
  if(is.null(k)){
    new_var_char <- paste0("s(", var, ")")
  } else{
    new_var_char <- paste0("s(", var, ", k = ", k, ")")
  }
  return(new_var_char)
}

# spline_vars <- c("charges", "age")
# form <- formula(mod_nb_withint)
# Function to update glm formula to gam
gam_update_form <- function(form, spline_vars){
  # Remove spline vars from main effect
  fterms <- terms(form)
  gam_spline_vars <- spline_vars %>%  # vars to add spline
    map_chr(add_spline) %>% # add spline
    paste(., collapse = "+") # concat them with "+"
  
  # Find index of vars to remove
  rm_spline_vars_inx <- spline_vars %>% 
    map_chr(., function(x) paste0("^", x, "$")) %>% # only remove main effect vars
    map_int(., function(x) grep(x, attr(mod_nb_withint$terms, "term.labels"))) 
  
  # Drop terms used in spline
  new_form <- drop.terms(fterms, dropx = rm_spline_vars_inx, keep.response = TRUE)
  # Add terms with spline
  new_form <- update(new_form, paste("~ . +", gam_spline_vars))
  return (new_form)
}
```

```{r}
spline_vars <- c("charges", "age")
gam_form <- gam_update_form(formula(mod_nb_withint), spline_vars) %>% formula()
neg_bin_gam <- gam(gam_form, family = nb(), data = ami_train)
```

```{r}
summary(neg_bin_gam)
```

# Likelihood ratio test between GLM and GAM
```{r}
# refit gam to fit into anova
ami_train <- ami_train %>% 
  mutate(
    charges_7 = (charges - mean(charges)) ^ 7,
    age_4 = (charges - mean(charges)) ^ 4
  )

# update formula to be glm
newvars <- c("charges_7", "age_4")
gam_glm_form <- attr(neg_bin_gam$terms, "term.labels") %>% 
  paste(., collapse = "+") %>% 
  paste(., paste(newvars, collapse ="+"), sep = "+") %>% 
  paste("los ~", .)

# Refit a glm with GAM variables
neg_bin_gam_glm <- glm.nb(formula(gam_glm_form), data = ami_train)
anova(mod_nb_withint, neg_bin_gam_glm, test = "Chi")
```

From the above result, we can see the GAM model (refitted in GLM) with smoothed variables (`charges_7` and `age_4`) is significantly better than the previous GLM model.

# GAM Model Diagnosis
```{r}
plot(neg_bin_gam, residuals = TRUE, shade=TRUE, shade.col = 2)
```
From the above chart, we can see the transformation of `charges` is nonlinear, particuarly, we see a piecewise linear relationship with a change at around 10000, where the transformation betcomes negative. 

linear term would be sufficient. In the case of
ibt, we see that a horizontal line at zero would fit between the bands. This suggests
this predictor has no marginal effect on the response.


# Test-set performance using final model - GAM
We will evaluate our test-set performance using RMSE.
```{r}
pred <- predict(neg_bin_gam, ami_test %>% dplyr::select(-los), type = "response")
rmse_vec(ami_test$los, pred)
```
