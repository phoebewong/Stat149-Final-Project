---
title: "Gamma"
author: "Nick Stern"
date: "4/28/2019"
output: 
  html_document:
    theme: flatly
    highlight: tango
    toc: true
    toc_float: true
    fig_width: 6
    fig_height: 4
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Abstract

This R markdown file serves to fit a Gamma model to the response data. The motivation for this is because the response variable exhibits right-skewness. See the exploratory data analysis notebook for visuals in support of this claim.

```{r message=FALSE, warning=FALSE}
library(mgcv)
library(tidymodels)
library(ggplot2)
library(car)
```


# Pre-Processing
- mean-imputed on charges and added charges.na
- Drop `Patient` ID column because of irrelevance
- Drop `DIED` column because of perfect colinearity with `DRG` (`DRG` == 123 when `DIED` == 1) 

```{r}
ami_init = readRDS("../../data/amidata_clean.rds")
drops <- c("patient","died")
ami = ami_init[ , !(names(ami_init) %in% drops)]
```

## Cross-validation
- We split the data with 80% in training set and 20% on a held-out test set for model evaluation. We set the random seed at 42 to ensure consistency across models.

```{r message=FALSE, warning=FALSE}
# Split data
set.seed(42)
ami_split <- initial_split(ami, prop = .8, strata = "los") # Stratified sampling based on LOS
ami_train <- training(ami_split)
ami_test  <- testing(ami_split)
```


# Fitting the Gamma GLM

### Discussion of zero-valued observation

Before we can fit the Gamma GLM, we need to deal with the one observation that has a response value of zero, as the Gamma distribution is defined for all positive continuous numbers. Note that our response variable is discrete, but time itself is a continuous metric, and we can think of the response variable as an aggregated form of a continuous latent variable. We first examined the details of the zero-valued observation to see if there was anything awry. 


```{r}
ami[ami$los == 0, ]
table(ami$los)[1:15]
```

From the information about the zero-valued datapoint, we do not see anything that is unbelievable or any feature that would insinuate this point is an outlier besides the length of stay. Without information on how the data were collected, we can't know apriori whether this datapoint was a result of data misentry, a violation of hospital policies, or a medical miracle. We can, however, compare the distribution of length of stay for patients with the same diagnosis with the overall population to see if perhaps there is a discrepancy between groups.


```{r message=FALSE}
# Examination of diagnosis
ggplot(data=ami, aes(x=los)) +
    geom_histogram(data=subset(ami, diagnosis == 41091), aes(fill='41091'), alpha = 0.2) +
    geom_histogram(alpha = 0.2, aes(fill='All')) + 
    scale_fill_manual(name="Diagnosis", values=c('red', 'blue'))
```

The results indicate that the diagnosis is representative of the overall population, and therefore the mixed effects hypothesis is not a valid reason for why we are seeing an outlier. This makes sense contextually since the diagnosis code 41091 represents "Acute myocardial infarction of unspecified site, initial episode of care - as a primary diagnosis." The "unspecified site" likely means it is a catchall diagnosis and spans a wide range of severity.

We can also look at the length of stay for the patients who died to see if there is a peak at 1 day. Our suspicion is that of the patients who died, a considerable number of them would have died the same day, as survival is extremely short-term when the heart stops beating. 

```{r}
hist(subset(ami_init$los, ami_init$died == 1), breaks=40, 
     xlab='Length of Stay', main='Histogram of Length of Stay Given Patient Died')
```

We do see a considerable peak at 1 day. This observation is convincing, but Professor Glickman pointed out that if the length of stay is based around the completion of paperwork, it is possible that patients who die the same day do not have their paperwork completed until the next. 

Taking everything into consideration, we are left with a few options:

1. Remove the datapoint under the assumption that it was incorrectly entered, using the length of stay distribution for those who died as evidence that same-day discharge is equivalent to a length of stay of 1.

2. Remove the datapoint under the assumption that it was correctly entered, effectively imposing a floor on our data and reflecting that in the model inference.

3. Shift all the response values by +1 under the assumption that the datapoint is accurate, and there is one person who was discharged and/or had their paperwork completed on the same day. Adjust the model interpretation correspondingly.

4. Change the datapoint to be 1, under the assumption that the data was generated using some kind of rounding to the nearest day, and to coincide with what we would likely do with our Gamma model's predictions that fall below 0.5. 

We also considered the option of fitting a hurdle model to the data, where the zero population would come from a binomial distribution and the rest of the data would come from a Gamma distribution. However, we determined it was not meaningful to fit a model parameter to a single datapoint, thereby electing to forgo this approach.

Ultimately, we chose to round the zero-valued datapoint to 1. This decision was motivated in large part by the mechanics of what would happen to a Gamma model prediction that was close to 0 (we would end up rounding this value to the nearest positive integer anyway), and also from the fact that removing a single, non-influential (none of the feature values were extreme) datatpoint from a dataset of more than 12,000 patients will have little to no effect on the predictions of our model. 

```{r}
ami_train$los[ami_train$los == 0] = 1
ami_test$los[ami_test$los == 0] = 1
```

### Feature Selection

We chose our best fit model using stepwise feature selection. The stepwise regression uses an iterative forward/backward selection method and the AIC criterion to choose the best model. To get a baseline, we first ran stepwise feature selection without interaction terms. Note, we removed patient id since there should be no causal connection between the patient id and the length of stay if the data were appropriately randomized.

```{r, eval=FALSE}
# Without interaction terms
step_noint = stats::step(glm(los ~ ., family=Gamma(log), data=ami_train), trace=0, direction='both')
# With interaction terms
step_int = stats::step(glm(los ~ .^2, family=Gamma(log), data=ami_train), trace=0, direction='both')

# Save model
save(step_noint, file = 'step_noint.rds')
save(step_int, file = "step_int.rds")
```

Next, we ran stepwise feature selection with all the interaction terms considered (of which there are many due to the multi-level factors in our dataset), to compare with our baseline.  

```{r load-model, include=FALSE}
# Load pre-trained model
load('step_noint.rds')
load('step_int.rds')
```

We then examined the summaries of both models.

```{r}
# No interaction model
gamma_noint = glm(formula = formula(step_noint), family = Gamma(log), data = ami_train)
summary(gamma_noint)
```

```{r}
# Interaction model
gamma_int = glm(formula = formula(step_int), family = Gamma(log), data = ami_train)
summary(gamma_int)
```

In both model summaries, ```charges``` and ```charges.na``` appear to be significant predictors. Therefore we decided to keep the imputation as a part of the model. 

We carried out a likelihood ratio test to see whether the model with interaction terms results in a significantly better fit.

```{r}
anova(gamma_noint, gamma_int, test='Chisq')
```

The likelihood ratio test indicates that the model with interaction terms has significantly less residual deviance than the model without, therefore we chose to continue our analysis with the interaction model.

As diagnostics to evaluate the fit of our model, we produced a plot of residual deviance and Cook's distances.

```{r fig.height=6, fig.width=10}
par(mfrow=c(1,2))
# Residuals plot
gamma.fitted = fitted(gamma_int)
gamma.devresid = residuals(gamma_int, type="deviance")
plot(gamma.fitted, gamma.devresid, xlab="Fitted counts", ylab="Deviance residuals", pch=19, col="red", cex=1.5, main="Gamma: Fitted vs Deviance Residual Plot")
abline(h=0,lty=2,col="black")
abline(h=2,lty=2,col="black")
abline(h=-2,lty=2,col="black")

# Cook's distance plot
plot(cooks.distance(gamma_int), type="h", lwd=2,
  xlab="Observation index",
  ylab="Cook's distances",
  main="Cook's Distances Plot")
abline(h=1,lty=2,col="red")
```


We expect the deviance residuals to approximately follow a standard normal distribution. The residuals plot indicates that the spread of the residuals does stay within the +/- 2 threshold, but they are not symmetrically scattered. In particular, it seems like the Gamma model severely overestimates the length of stay for larger points, predicting values as high as 200 days when the maximum observed value is 38 days. The Cook's distance plot shows there are no influential points of note. 

Finally, we examined the potential for collinearity using the Variance Inflation Factor (VIF).

```{r message=FALSE, warning=FALSE}
vif(gamma_int)
```

There are a number of terms with a GVIF^(1/(2*Df)) greater than $\sqrt{10}$, though we suspect this is due to the presence of interaction terms. We therefore fit the baseline model without interaction terms and redid the VIF inspection.

```{r}
baseline_model = glm(formula = los ~ diagnosis + sex + drg + charges + 
    age + charges.na, family = Gamma(log), data = ami_train)
vif(baseline_model)
```

These values are all much less than $\sqrt{10}$, suggesting there is no multicollinearity in the base predictors, and the multicollinearity present in the full model comes from the interaction terms.

# GAM Model

We also explored using a Generalized Additive Model where we explore the application of nonlinear smooths to our GLM predictors. We can write out our linear predictor as following.

$g(\mu_i) = \beta_0 + S_1(x_{i1}) + ... +S_j(x_{ij})$

Individual $S_j$ functions refer to smooths applied to predictors.


```{r eval=FALSE, message=FALSE, warning=FALSE}
# GAM
gamma_gam = gam(formula = los ~ diagnosis + sex + drg + s(charges) + s(age)
                + charges.na + diagnosis:drg + diagnosis:charges + sex:age
                + drg:charges + drg:age + drg:charges.na + charges:age, data = ami_train, family = Gamma(log))

save(gamma_gam, file='gamma_gam.rds')
```

```{r}

load('gamma_gam.rds')
summary(gamma_gam)
```


We then perform a likelihood ratio between GLM and GAM to determine our final model for negative binomial model family. We needed to refit the GAM as a `glm` object, because of the limitation in `anova()` in R. We refitted the GAM using the same predictor and non-linear transformation suggested in the GAM model.

```{r}
# ANOVA between GLM and GAM 
anova(gamma_int, gamma_gam, test='Chisq')
```

The results of the likelihood ratio test indicate that the GAM model with interaction terms is significantly better than the GLM with interaction terms.

```{r}
plot(gamma_gam, residuals = TRUE, shade=TRUE, shade.col = 2)
```

```{r fig.height=6, fig.width=10}
par(mfrow=c(1,2))
# Residuals plot
gamma.fitted = fitted(gamma_gam)
gamma.devresid = residuals(gamma_gam, type="deviance")
plot(gamma.fitted, gamma.devresid, xlab="Fitted counts", ylab="Deviance residuals", pch=19, col="red", cex=1.5, main="Gamma: Fitted vs Deviance Residual Plot")
abline(h=0,lty=2,col="black")
abline(h=2,lty=2,col="black")
abline(h=-2,lty=2,col="black")

# Cook's distance plot
plot(cooks.distance(gamma_gam), type="h", lwd=2,
  xlab="Observation index",
  ylab="Cook's distances",
  main="Cook's Distances Plot")
abline(h=1,lty=2,col="red")
```

The fitted counts and the nonlinearity of the residuals improves a lot with the addition of the smooths!
```{r}
# Training Set evaluation
train_pred <- predict(gamma_gam, ami_train %>% dplyr::select(-los), type = "response")
rmse_vec(ami_train$los, train_pred)
```


```{r}
# Test Set evaluation
test_pred <- predict(gamma_gam, ami_test %>% dplyr::select(-los), type = "response")
rmse_vec(ami_test$los, test_pred)
```

